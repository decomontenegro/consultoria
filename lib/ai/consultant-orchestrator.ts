/**
 * AI Consultant Orchestrator - PhD Virtual Consultant
 *
 * Purpose: Use LLM (Claude) to generate dynamic follow-up questions
 * based on user responses, like a real business consultant would.
 *
 * Techniques:
 * - SPIN Selling: Situation → Problem → Implication → Need-Payoff
 * - 5 Whys: Dig deeper into root causes
 * - Socratic Method: Question assumptions
 * - Weak Signal Detection: Spot vagueness, contradictions, hesitations
 *
 * Cost Model (Hybrid):
 * - 6 essential questions: R$0 (scripted)
 * - 2-4 dynamic follow-ups: R$0.30-0.60 (LLM)
 * - Final insights: R$0.60 (LLM)
 * Total: ~R$0.50-1.20 per assessment
 */

import Anthropic from '@anthropic-ai/sdk';
import { UserPersona } from '../types';

// ============================================
// TYPES
// ============================================

/**
 * Response Analysis - What the LLM detected in user's answer
 */
export interface ResponseAnalysis {
  // Weak signals detected
  weakSignals: {
    isVague: boolean; // "não sei", "mais ou menos", "depende"
    hasContradiction: boolean; // Says X then says not-X
    hasHesitation: boolean; // "talvez", "acho que", "provavelmente"
    lacksMetrics: boolean; // No numbers, no concrete data
    hasEmotionalLanguage: boolean; // "frustrado", "desesperado", "preocupado"
  };

  // Key insights extracted
  insights: {
    urgencyLevel: 'low' | 'medium' | 'high' | 'critical';
    hasQuantifiableImpact: boolean;
    mentionedCompetitors: boolean;
    mentionedDeadline: boolean;
    hasDecisionAuthority: boolean; // "eu aprovo", "preciso de CEO"
  };

  // Suggested follow-up direction
  followUpDirection:
    | 'quantify-impact' // "você mencionou problemas, consegue quantificar?"
    | 'dig-deeper-root-cause' // "por que isso acontece?" (5 Whys)
    | 'challenge-assumption' // "você disse X, mas também Y - qual é verdade?"
    | 'explore-constraint' // "o que te impede de resolver agora?"
    | 'validate-commitment' // "se eu mostrar ROI, você investe?"
    | 'skip-to-next'; // Response is complete, no follow-up needed
}

/**
 * Orchestrator Context - Everything we know so far
 */
export interface OrchestratorContext {
  persona: UserPersona | null;
  conversationHistory: Array<{
    question: string;
    answer: string;
    questionId: string;
    metrics?: Record<string, any>;
  }>;
  currentQuestionId: string;
  currentQuestionPhase: 'situation' | 'problem' | 'implication' | 'need-payoff';
  followUpsAsked: number; // Track how many LLM follow-ups used
  maxFollowUps: number; // Budget limit (default: 3)
}

/**
 * Follow-up Question Generated by LLM
 */
export interface DynamicFollowUp {
  question: string;
  reasoning: string; // Why this follow-up is important
  expectedExtraction: string[]; // What we're trying to extract
  type: 'quantify' | 'clarify' | 'dig-deeper' | 'challenge';
}

// ============================================
// ANTHROPIC CLIENT
// ============================================

const anthropic = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY || ''
});

// ============================================
// RESPONSE ANALYZER
// ============================================

/**
 * Analyze user's answer to detect weak signals and insights
 * Uses Claude API to deeply understand the response
 */
export async function analyzeResponse(
  question: string,
  answer: string,
  context: OrchestratorContext
): Promise<ResponseAnalysis> {
  const conversationContext = context.conversationHistory
    .map(
      (item) => `Q: ${item.question}\nA: ${item.answer}\n${item.metrics ? `Metrics: ${JSON.stringify(item.metrics)}` : ''}`
    )
    .join('\n\n');

  const analysisPrompt = `You are a PhD business consultant analyzing a client's response during discovery.

**Conversation so far:**
${conversationContext}

**Current Question:**
${question}

**Client's Answer:**
"${answer}"

**Your Task:**
Analyze this answer deeply and return a JSON object with:

1. **weakSignals**: Detect if the answer is:
   - vague (lacks specifics, uses "mais ou menos", "não sei")
   - contradictory (says X then says not-X)
   - hesitant (uses "talvez", "acho que", "provavelmente")
   - lacks metrics (no numbers, no concrete data)
   - has emotional language ("frustrado", "preocupado", "desesperado")

2. **insights**: Extract business insights:
   - urgencyLevel: how urgent is their problem? (low/medium/high/critical)
   - hasQuantifiableImpact: did they mention measurable impact? (lost customers, R$ cost, delays)
   - mentionedCompetitors: are competitors mentioned?
   - mentionedDeadline: is there a specific deadline/timeline?
   - hasDecisionAuthority: can they approve budget or need approval?

3. **followUpDirection**: What's the BEST follow-up strategy?
   - "quantify-impact": they mentioned problem but no numbers → ask for metrics
   - "dig-deeper-root-cause": surface-level answer → ask WHY this happens
   - "challenge-assumption": contradictory statements → clarify which is true
   - "explore-constraint": they want to solve but haven't → ask what blocks them
   - "validate-commitment": check if they'll actually invest if ROI shown
   - "skip-to-next": answer is complete, no follow-up needed

**Return ONLY valid JSON, no markdown:**

{
  "weakSignals": {
    "isVague": boolean,
    "hasContradiction": boolean,
    "hasHesitation": boolean,
    "lacksMetrics": boolean,
    "hasEmotionalLanguage": boolean
  },
  "insights": {
    "urgencyLevel": "low" | "medium" | "high" | "critical",
    "hasQuantifiableImpact": boolean,
    "mentionedCompetitors": boolean,
    "mentionedDeadline": boolean,
    "hasDecisionAuthority": boolean
  },
  "followUpDirection": "quantify-impact" | "dig-deeper-root-cause" | "challenge-assumption" | "explore-constraint" | "validate-commitment" | "skip-to-next"
}`;

  console.log('[Orchestrator] Analyzing response via Claude...');

  const message = await anthropic.messages.create({
    model: 'claude-haiku-4-5-20251001', // Haiku 4.5: adequate for follow-up analysis
    max_tokens: 1024,
    temperature: 0.3, // Lower temp for more consistent analysis
    messages: [
      {
        role: 'user',
        content: analysisPrompt
      }
    ]
  });

  const responseText = message.content[0].type === 'text' ? message.content[0].text : '';

  // Parse JSON response
  const jsonMatch = responseText.match(/\{[\s\S]*\}/);
  if (!jsonMatch) {
    throw new Error('Failed to parse analysis response');
  }

  const analysis: ResponseAnalysis = JSON.parse(jsonMatch[0]);

  console.log('[Orchestrator] Analysis complete:', {
    weakSignals: analysis.weakSignals,
    urgency: analysis.insights.urgencyLevel,
    direction: analysis.followUpDirection
  });

  return analysis;
}

// ============================================
// DYNAMIC FOLLOW-UP GENERATOR
// ============================================

/**
 * Generate a contextual follow-up question via Claude API
 */
export async function generateFollowUp(
  analysis: ResponseAnalysis,
  context: OrchestratorContext
): Promise<DynamicFollowUp | null> {
  // Skip if no follow-up needed
  if (analysis.followUpDirection === 'skip-to-next') {
    console.log('[Orchestrator] No follow-up needed, answer is complete');
    return null;
  }

  // Budget check: max follow-ups reached?
  if (context.followUpsAsked >= context.maxFollowUps) {
    console.log('[Orchestrator] Max follow-ups reached, skipping');
    return null;
  }

  const lastQA = context.conversationHistory[context.conversationHistory.length - 1];

  const conversationContext = context.conversationHistory
    .map((item) => `Q: ${item.question}\nA: ${item.answer}`)
    .join('\n\n');

  const personaContext = context.persona
    ? `User is a ${context.persona} (adapt language accordingly)`
    : 'Persona unknown';

  const followUpPrompt = `You are a PhD business consultant conducting discovery with a potential client.

**Persona:** ${personaContext}

**Conversation so far:**
${conversationContext}

**Analysis of last answer:**
- Weak signals: ${JSON.stringify(analysis.weakSignals)}
- Insights: ${JSON.stringify(analysis.insights)}
- Follow-up direction: ${analysis.followUpDirection}

**Your Task:**
Generate ONE powerful follow-up question that:

1. **Follows the direction:** ${analysis.followUpDirection}
   - If "quantify-impact": Ask for specific numbers (R$ lost, customers churned, hours wasted)
   - If "dig-deeper-root-cause": Ask WHY this problem exists (5 Whys technique)
   - If "challenge-assumption": Point out contradiction and ask for clarification
   - If "explore-constraint": Ask what prevents them from solving this now
   - If "validate-commitment": Check if they'll invest if you prove ROI

2. **Is consultative, not salesy:** Sound like a trusted advisor, not a pushy salesperson

3. **Is specific, not generic:** Reference their exact situation, use their words

4. **Extracts actionable data:** Aim to get metrics, names, deadlines, constraints

**Return ONLY valid JSON, no markdown:**

{
  "question": "The follow-up question in Portuguese (PT-BR)",
  "reasoning": "Why this question is critical at this moment",
  "expectedExtraction": ["metric1", "metric2", "..."],
  "type": "quantify" | "clarify" | "dig-deeper" | "challenge"
}

**Example (quantify-impact):**
{
  "question": "Você mencionou que perdem clientes por lentidão. Consegue estimar quantos clientes churned nos últimos 6 meses por isso? E qual o ticket médio deles?",
  "reasoning": "Client mentioned customer loss but didn't quantify. Need ARR impact to calculate ROI.",
  "expectedExtraction": ["customers_churned", "average_arr", "churn_reason"],
  "type": "quantify"
}`;

  console.log('[Orchestrator] Generating follow-up via Claude...');

  const message = await anthropic.messages.create({
    model: 'claude-haiku-4-5-20251001', // Haiku 4.5: good for generating questions
    max_tokens: 512,
    temperature: 0.7, // Slightly higher for more natural questions
    messages: [
      {
        role: 'user',
        content: followUpPrompt
      }
    ]
  });

  const responseText = message.content[0].type === 'text' ? message.content[0].text : '';

  // Parse JSON response
  const jsonMatch = responseText.match(/\{[\s\S]*\}/);
  if (!jsonMatch) {
    throw new Error('Failed to parse follow-up response');
  }

  const followUp: DynamicFollowUp = JSON.parse(jsonMatch[0]);

  console.log('[Orchestrator] Generated follow-up:', {
    type: followUp.type,
    questionPreview: followUp.question.substring(0, 80) + '...'
  });

  return followUp;
}

// ============================================
// ORCHESTRATOR MAIN FUNCTION
// ============================================

/**
 * Main orchestrator: Analyze response → Decide if follow-up needed → Generate follow-up
 */
export async function orchestrateFollowUp(
  questionId: string,
  question: string,
  answer: string,
  context: OrchestratorContext
): Promise<{
  shouldAskFollowUp: boolean;
  followUp: DynamicFollowUp | null;
  analysis: ResponseAnalysis;
  cost: number; // Estimated cost in BRL
}> {
  console.log(`[Orchestrator] Processing answer for ${questionId}...`);

  // Step 1: Analyze response
  const analysis = await analyzeResponse(question, answer, context);

  // Step 2: Decide if follow-up is needed
  if (analysis.followUpDirection === 'skip-to-next') {
    return {
      shouldAskFollowUp: false,
      followUp: null,
      analysis,
      cost: 0.15 // Analysis only (~500 tokens)
    };
  }

  // Step 3: Generate follow-up
  const followUp = await generateFollowUp(analysis, context);

  if (!followUp) {
    return {
      shouldAskFollowUp: false,
      followUp: null,
      analysis,
      cost: 0.15 // Analysis only
    };
  }

  return {
    shouldAskFollowUp: true,
    followUp,
    analysis,
    cost: 0.30 // Analysis + generation (~1000 tokens)
  };
}

// ============================================
// HELPER: Build Context
// ============================================

/**
 * Build orchestrator context from conversation history
 */
export function buildOrchestratorContext(
  persona: UserPersona | null,
  conversationHistory: Array<{
    questionId: string;
    question: string;
    answer: string;
    metrics?: Record<string, any>;
  }>,
  currentQuestionId: string,
  maxFollowUps: number = 3
): OrchestratorContext {
  return {
    persona,
    conversationHistory,
    currentQuestionId,
    currentQuestionPhase: inferPhaseFromQuestionId(currentQuestionId),
    followUpsAsked: conversationHistory.filter((item) =>
      item.questionId.includes('followup')
    ).length,
    maxFollowUps
  };
}

function inferPhaseFromQuestionId(
  questionId: string
): 'situation' | 'problem' | 'implication' | 'need-payoff' {
  if (questionId.includes('operational-baseline') || questionId.includes('team-context')) {
    return 'situation';
  }
  if (questionId.includes('quantified-pain')) {
    return 'problem';
  }
  if (questionId.includes('cost-of-inaction')) {
    return 'implication';
  }
  return 'need-payoff';
}
