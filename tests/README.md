# Estudo de UX - Consulta AI Multi-Persona

## ğŸ“‹ VisÃ£o Geral

Este diretÃ³rio contÃ©m um estudo abrangente de UX testando o fluxo de consulta AI com **5 personas Ã— 5 cenÃ¡rios = 25 testes E2E**.

### Estrutura

```
tests/
â”œâ”€â”€ mocks/
â”‚   â””â”€â”€ claude-mock.ts          # Mock da API Anthropic (respostas simuladas)
â”œâ”€â”€ fixtures/
â”‚   â””â”€â”€ persona-scenarios.ts    # 25 cenÃ¡rios de teste
â”œâ”€â”€ analysis/
â”‚   â””â”€â”€ analyze-results.ts      # Script de anÃ¡lise de resultados
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ test-results-*.json     # Resultados brutos (JSON)
â”‚   â””â”€â”€ persona-study-report-*.md # RelatÃ³rio final (Markdown)
â””â”€â”€ ai-consultation-personas.spec.ts # Testes E2E com Playwright
```

## ğŸ¯ Personas Testadas

1. **board-executive** - Executivo C-Level / Conselho
2. **finance-ops** - Executivo FinanÃ§as / OperaÃ§Ãµes
3. **product-business** - LÃ­der Produto / NegÃ³cios
4. **engineering-tech** - LÃ­der Engenharia / Tecnologia
5. **it-devops** - Gerente TI / DevOps

## ğŸ“Š CenÃ¡rios por Persona

Cada persona Ã© testada com 5 cenÃ¡rios diferentes:

1. **Otimista** - Empresa crescendo, quer acelerar
2. **Pessimista** - Muitos problemas, baixa confianÃ§a
3. **Realista** - Misto de desafios e oportunidades
4. **CÃ©tico** - Resistente a AI, precisa ROI provado
5. **Urgente** - Problemas crÃ­ticos, timeline agressivo

## ğŸš€ Como Executar

### 1. PrÃ©-requisitos

```bash
# Instalar dependÃªncias (se necessÃ¡rio)
npm install

# Garantir que servidor dev estÃ¡ rodando
npm run dev
```

### 2. Executar Todos os 25 Testes

```bash
# OpÃ§Ã£o 1: Via Playwright UI (recomendado para debug)
npx playwright test --ui tests/ai-consultation-personas.spec.ts

# OpÃ§Ã£o 2: Via linha de comando
npx playwright test tests/ai-consultation-personas.spec.ts

# OpÃ§Ã£o 3: Apenas uma persona especÃ­fica
npx playwright test tests/ai-consultation-personas.spec.ts --grep "board-executive"
```

### 3. Analisar Resultados

```bash
# Gerar relatÃ³rio de anÃ¡lise
npx ts-node tests/analysis/analyze-results.ts
```

## ğŸ“ˆ MÃ©tricas Coletadas

Para cada um dos 25 testes:

- **TÃ³picos Sugeridos** - Quantos e se sÃ£o apropriados ao perfil
- **Perguntas Feitas** - Quantidade e adequaÃ§Ã£o ao nÃ­vel de abstraÃ§Ã£o
- **Fluxo da Conversa** - Se opÃ§Ã£o "Continuar/Finalizar" aparece
- **JargÃ£o TÃ©cnico** - Uso inadequado em perfis nÃ£o-tÃ©cnicos
- **Insights Salvos** - Se seÃ§Ã£o aparece corretamente no report

## ğŸ“„ RelatÃ³rio Final

O relatÃ³rio gerado inclui:

### Executive Summary
- Taxa de sucesso geral
- EstatÃ­sticas agregadas

### AnÃ¡lise por Persona
- Performance de cada perfil
- Problemas comuns
- Resultados por cenÃ¡rio

### AnÃ¡lise por CenÃ¡rio
- Qual tipo de cenÃ¡rio funciona melhor
- Problemas especÃ­ficos

### Problemas CrÃ­ticos
- Issues que afetam mÃºltiplos testes
- FrequÃªncia e impacto

### RecomendaÃ§Ãµes Priorizadas
- **P0 (CrÃ­tico)** - Issues que afetam 5+ testes
- **P1 (Alto)** - Problemas de persona especÃ­fica
- **P2 (MÃ©dio)** - Melhorias de cenÃ¡rio
- **P3 (Baixo)** - Nice-to-haves

## ğŸ§ª Exemplo de Resultado

```markdown
## ğŸ“Š Executive Summary

- **Taxa de Sucesso:** 92.0%
- **Testes Passados:** 23/25
- **Testes Falhados:** 2/25

## ğŸ­ AnÃ¡lise por Persona

| Persona           | Testes | Passou | Score Topics | Flow OK |
|-------------------|--------|--------|--------------|---------|
| board-executive   | 5      | 5 (100%) | 80%        | 100%    |
| finance-ops       | 5      | 5 (100%) | 100%       | 100%    |
| product-business  | 5      | 4 (80%)  | 60%        | 100%    |
| engineering-tech  | 5      | 5 (100%) | 100%       | 100%    |
| it-devops         | 5      | 4 (80%)  | 80%        | 80%     |
```

## ğŸ” O Que Ã‰ Testado

### âœ… ValidaÃ§Ãµes Positivas

- TÃ³picos gerados sÃ£o relevantes ao perfil?
- Perguntas usam linguagem adequada (negÃ³cio vs tÃ©cnica)?
- Fluxo nÃ£o corta conversa abruptamente?
- UsuÃ¡rio tem controle (pode continuar ou finalizar)?
- Insights salvos e exibidos no report?

### âŒ ValidaÃ§Ãµes Negativas

- Board Executive recebe perguntas sobre "dÃ©bito tÃ©cnico"?
- Finance/Ops recebe perguntas muito tÃ©cnicas?
- Engineering recebe perguntas muito superficiais?
- Fluxo forÃ§a usuÃ¡rio a responder 5 perguntas obrigatÃ³rias?

## ğŸ› ï¸ CustomizaÃ§Ã£o

### Adicionar Novo CenÃ¡rio

Edite `fixtures/persona-scenarios.ts`:

```typescript
const scenarioTemplates = {
  // ... existing scenarios
  meuNovoTipo: {
    currentState: { ... },
    goals: { ... },
    simulatedResponses: [ ... ],
  },
};
```

### Modificar Mock de Respostas

Edite `mocks/claude-mock.ts`:

```typescript
const personaResponses = {
  'board-executive': {
    question1: [{
      text: 'Sua pergunta customizada',
      isAppropriate: true,
      abstractionLevel: 'strategic',
    }],
  },
};
```

## ğŸ“Š Exportar Resultados

Resultados sÃ£o salvos automaticamente em:

- **JSON:** `reports/test-results-[timestamp].json`
- **Markdown:** `reports/persona-study-report-[timestamp].md`

Para exportar para Excel:
```bash
# Manual: Abrir JSON no Excel ou Google Sheets
```

## ğŸ› Troubleshooting

### Testes Falham com Timeout

```bash
# Aumentar timeout no playwright.config.ts
timeout: 60000, // 60 segundos
```

### Mock nÃ£o funciona

Verifique se servidor dev estÃ¡ rodando:
```bash
npm run dev
# Em outro terminal:
npx playwright test
```

### Resultados nÃ£o aparecem

```bash
# Criar diretÃ³rio manualmente
mkdir -p tests/reports
```

## ğŸ“ Contribuindo

Para melhorar os testes:

1. Adicione novos cenÃ¡rios em `fixtures/`
2. Melhore mocks em `mocks/`
3. Adicione mÃ©tricas em `analysis/`
4. Execute e compare resultados

## ğŸ¯ PrÃ³ximos Passos

ApÃ³s anÃ¡lise dos resultados:

1. Identificar personas problemÃ¡ticas
2. Ajustar prompts em `lib/prompts/`
3. Melhorar geraÃ§Ã£o de tÃ³picos
4. Re-executar testes
5. Validar melhorias

---

**DÃºvidas?** Consulte a documentaÃ§Ã£o principal ou abra uma issue.

---

# ğŸ§ª FASE 2 & FASE 3: API Tests (100% Real API)

Testes para Follow-up Orchestrator (FASE 2) e Insights Engine (FASE 3) usando chamadas reais Ã  API Claude.

## ğŸ“ Estrutura FASE 2 & 3

```
tests/
â”œâ”€â”€ mocks/                           Mocks (criados, nÃ£o usados)
â”‚   â”œâ”€â”€ claude-mock-followups.ts     287 linhas
â”‚   â””â”€â”€ claude-mock-insights.ts      296 linhas
â”œâ”€â”€ fixtures/                        CenÃ¡rios de teste
â”‚   â”œâ”€â”€ followup-scenarios.ts        7 cenÃ¡rios (199 linhas)
â”‚   â””â”€â”€ insights-scenarios.ts        4 cenÃ¡rios (354 linhas)
â”œâ”€â”€ fase2-followups/
â”‚   â””â”€â”€ followup-api.spec.ts         8 testes API (R$ 0.90/run)
â””â”€â”€ fase3-insights/
    â””â”€â”€ insights-api.spec.ts         8 testes API (R$ 2.40/run)
```

## ğŸš€ Quick Start

### 1. Configurar API Key

```bash
export ANTHROPIC_API_KEY=sk-ant-api-...
```

### 2. Iniciar Servidor

```bash
npm run dev
# Aguardar http://localhost:3000
```

### 3. Executar Testes

```bash
# Health checks (grÃ¡tis)
npx playwright test -g "GET health check"

# Follow-ups API (R$ 0.90)
npx playwright test tests/fase2-followups

# Insights API (R$ 2.40)
npx playwright test tests/fase3-insights

# Todos os API tests (R$ 3.30)
npx playwright test tests/fase2-followups tests/fase3-insights
```

## ğŸ’° Custos e Budget

| Suite | Testes | Custo | Tempo |
|-------|--------|-------|-------|
| Health checks | 2 | R$ 0.00 | 2s |
| Follow-ups | 8 | R$ 0.90 | ~15s |
| Insights | 8 | R$ 2.40 | ~20s |
| **Total** | **16** | **R$ 3.30** | **~30s** |

**Budget mensal:** R$ 127 (permite atÃ© 38 execuÃ§Ãµes completas/mÃªs)

## ğŸ“Š Testes Implementados

### FASE 2: Follow-up Orchestrator (8 testes)
- Health check da API
- AnÃ¡lise de respostas vÃ¡lidas
- DetecÃ§Ã£o de weak signals
- Limite de 3 follow-ups
- ValidaÃ§Ã£o de campos
- CenÃ¡rios: vague, complete, emotional

### FASE 3: Insights Engine (8 testes)
- Health check da API
- GeraÃ§Ã£o para high-value leads
- Skip para low-value leads
- Respeito a urgency
- ValidaÃ§Ã£o de campos obrigatÃ³rios
- Budget-aware logic
- Force generate override

## ğŸ”§ CaracterÃ­sticas TÃ©cnicas

- **ExecuÃ§Ã£o Serial:** Evita rate limits (50 req/min)
- **Timeouts:** 60s para chamadas Claude API
- **Delays:** 2s entre testes com API real
- **Cost Tracking:** AutomÃ¡tico via `lib/monitoring/cost-tracker.ts`

## ğŸ“š DocumentaÃ§Ã£o Completa

- **EstratÃ©gia de Testes:** [docs/TESTING_STRATEGY.md](../docs/TESTING_STRATEGY.md)
- **Resultados Finais:** [docs/TESTE_FINAL_RESULTS.md](../docs/TESTE_FINAL_RESULTS.md)
- **CI/CD Workflow:** [.github/workflows/test-playwright-api.yml](../.github/workflows/test-playwright-api.yml)

## ğŸ› Troubleshooting

**Timeout:** Verificar se servidor estÃ¡ em http://localhost:3000
**Rate Limit:** Testes jÃ¡ tÃªm delay, aguardar 1 minuto se necessÃ¡rio
**Budget Exceeded:** Aguardar atÃ© meia-noite ou aumentar limite

---

**VersÃ£o FASE 2&3:** 1.0.0 (Plan A - 100% API Real)
**Ãšltima atualizaÃ§Ã£o:** 2025-11-14

---

# ğŸ¯ Adaptive Assessment API Tests (100% Real API)

Testes de integraÃ§Ã£o para o sistema completo de Adaptive Assessment com 4 endpoints API usando chamadas reais ao Claude.

## ğŸ“ Estrutura

```
tests/
â””â”€â”€ adaptive-assessment/
    â””â”€â”€ adaptive-api.spec.ts        12 testes API (R$ 1.50-2.00/run)
```

## ğŸ”„ Endpoints Testados

1. **POST /api/adaptive-assessment** - Inicializar sessÃ£o
2. **POST /api/adaptive-assessment/next-question** - Obter prÃ³xima pergunta (usa AI router)
3. **POST /api/adaptive-assessment/answer** - Submeter resposta
4. **POST /api/adaptive-assessment/complete** - Finalizar assessment

## ğŸš€ Como Executar

### 1. PrÃ©-requisitos

```bash
# Configurar API Key
export ANTHROPIC_API_KEY=sk-ant-api-...

# Iniciar servidor dev
npm run dev
```

### 2. Executar Testes

```bash
# Todos os testes (R$ 1.50-2.00)
npx playwright test tests/adaptive-assessment

# Apenas happy paths (R$ 1.00-1.50)
npx playwright test tests/adaptive-assessment -g "Happy Paths"

# Apenas error handling (grÃ¡tis, sem Claude API)
npx playwright test tests/adaptive-assessment -g "Error Handling"

# Apenas edge cases (R$ 0.50-1.00)
npx playwright test tests/adaptive-assessment -g "Edge Cases"
```

## ğŸ“Š Testes Implementados (12 testes)

### Group 1: Happy Paths (5 testes)
1. **Initialize session successfully**
   - Cria sessÃ£o com persona vÃ¡lido
   - Verifica sessionId retornado
   - âœ… Custo: R$ 0.00

2. **Get first question (should not be null)**
   - ObtÃ©m primeira pergunta via AI router
   - Valida estrutura da pergunta
   - âœ… Custo: R$ 0.05-0.10 (Claude API)

3. **Submit answer and verify context update**
   - Submete resposta vÃ¡lida
   - Verifica atualizaÃ§Ã£o de contexto
   - âœ… Custo: R$ 0.00

4. **Complete flow (init â†’ 3-5 Q&A â†’ complete)**
   - Fluxo completo de assessment
   - Verifica progressÃ£o de completeness
   - Testa insights opcionalCusto: R$ 0.75-1.00 (3-5 chamadas Claude)

5. **Verify completeness progression**
   - Responde 3 perguntas
   - Valida aumento monotÃ´nico de completeness
   - âœ… Custo: R$ 0.45-0.60 (3 chamadas Claude)

### Group 2: Error Handling (5 testes)
6. **Error: Missing sessionId (next-question)**
   - Valida erro 400
   - âœ… Custo: R$ 0.00

7. **Error: Invalid persona (init)**
   - Valida erro 400
   - âœ… Custo: R$ 0.00

8. **Error: Session not found (next-question)**
   - Valida erro 404
   - âœ… Custo: R$ 0.00

9. **Error: Invalid question ID (answer)**
   - Valida erro 404
   - âœ… Custo: R$ 0.00

10. **Error: Missing answer (answer)**
    - Valida erro 400
    - âœ… Custo: R$ 0.00

### Group 3: Edge Cases (2 testes)
11. **Verify session cleanup after complete**
    - Valida que sessÃ£o Ã© deletada apÃ³s complete
    - Tenta reusar sessionId (deve falhar)
    - âœ… Custo: R$ 0.00

12. **Complete works even if insights fail (graceful degradation)**
    - Testa que complete funciona sem insights
    - Valida graceful degradation
    - âœ… Custo: R$ 0.10-0.20 (1-2 chamadas Claude)

## ğŸ’° Custos Estimados

| Categoria | Testes | Chamadas Claude | Custo |
|-----------|--------|----------------|-------|
| Happy Paths | 5 | 10-15 | R$ 1.25-1.75 |
| Error Handling | 5 | 0 | R$ 0.00 |
| Edge Cases | 2 | 1-3 | R$ 0.15-0.25 |
| **Total** | **12** | **11-18** | **R$ 1.50-2.00** |

**Budget mensal:** R$ 127 (permite atÃ© 60-80 execuÃ§Ãµes/mÃªs)

## ğŸ¯ O Que Ã‰ Testado

### âœ… ValidaÃ§Ãµes Principais

**Session Management:**
- CriaÃ§Ã£o de sessÃ£o com persona vÃ¡lido
- ValidaÃ§Ã£o de sessionId
- Session cleanup apÃ³s complete
- DetecÃ§Ã£o de session expired/not found

**Question Routing (AI-powered):**
- AI router seleciona pergunta apropriada
- Estrutura da pergunta vÃ¡lida (id, text, inputType, options)
- shouldFinish detecta quando completar
- Routing decision com reasoning

**Answer Processing:**
- Context atualizado corretamente
- Completeness score aumenta monotonicamente
- Topics detectados semanticamente
- ValidaÃ§Ã£o de questionId e answer

**Assessment Completion:**
- AssessmentData compilado corretamente
- SessionSummary com mÃ©tricas
- Insights opcionaliais (graceful degradation)
- Session deletada apÃ³s complete

**Error Handling:**
- Missing sessionId â†’ 400
- Invalid persona â†’ 400
- Session not found â†’ 404
- Invalid questionId â†’ 404
- Missing answer â†’ 400

## ğŸ”§ CaracterÃ­sticas TÃ©cnicas

**ExecuÃ§Ã£o:**
- **Serial mode:** Gerencia estado de sessÃ£o sequencialmente
- **Timeouts:** 60-120s para testes com mÃºltiplas chamadas Claude
- **Delays:** 2s entre testes para rate limiting
- **Real API:** Testa integraÃ§Ã£o real (nÃ£o mock)

**Session State:**
- In-memory storage (session-manager)
- 30min timeout (nÃ£o testado, seria muito longo)
- Cleanup automÃ¡tico a cada 5min
- Delete explÃ­cito em complete

**AI Router:**
- Claude API: claude-3-5-sonnet-20250122
- ~300 tokens por decisÃ£o
- Fallback rule-based se Claude falhar
- Completeness-aware (para atÃ© 80%)

## ğŸ“ˆ Fluxo de Teste TÃ­pico

```
1. POST /api/adaptive-assessment
   â†’ sessionId: "abc123"

2. POST /api/adaptive-assessment/next-question
   â†’ nextQuestion: { id: "company-industry-v2", ... }
   â†’ completeness: 15%

3. POST /api/adaptive-assessment/answer
   â†’ success: true
   â†’ completeness: 28%

4. (Repetir 2-3 mais 2-4 vezes)
   â†’ completeness: 45% â†’ 62% â†’ 78%

5. POST /api/adaptive-assessment/next-question
   â†’ shouldFinish: true
   â†’ finishReason: "completeness_reached"

6. POST /api/adaptive-assessment/complete
   â†’ assessmentData: { ... }
   â†’ sessionSummary: { questionsAsked: 5, completeness: 78% }
   â†’ deepInsights: { ... } (opcional)
```

## ğŸ› Troubleshooting

**Timeout em testes:**
- Verificar servidor em http://localhost:3000
- Aumentar timeout para 120s em testes longos
- Verificar ANTHROPIC_API_KEY configurado

**Rate limit:**
- Testes jÃ¡ tÃªm 2s delay
- Se necessÃ¡rio, aumentar RATE_LIMIT_DELAY
- Aguardar 1 minuto entre execuÃ§Ãµes completas

**Session not found:**
- Normal apÃ³s complete (session deletada)
- Verificar que cada teste cria sessÃ£o nova
- Checar logs do servidor para detalhes

**Completeness nÃ£o aumenta:**
- Verificar se perguntas estÃ£o sendo respondidas corretamente
- Checar logs do answer endpoint
- Validar que questionId estÃ¡ correto

## ğŸ“š Arquivos Relacionados

**API Endpoints:**
- `/app/api/adaptive-assessment/route.ts` - InicializaÃ§Ã£o
- `/app/api/adaptive-assessment/next-question/route.ts` - AI router
- `/app/api/adaptive-assessment/answer/route.ts` - Context update
- `/app/api/adaptive-assessment/complete/route.ts` - FinalizaÃ§Ã£o

**Core Logic:**
- `/lib/ai/session-manager.ts` - Gerenciamento de sessÃµes
- `/lib/ai/adaptive-question-router.ts` - AI-powered routing
- `/lib/ai/conversation-context.ts` - Context updates
- `/lib/ai/completeness-scorer.ts` - MÃ©tricas de completude
- `/lib/ai/question-pool.ts` - Pool de 50 perguntas

## ğŸ¯ DecisÃµes de Design (ULTRATHINK)

**Por que 100% Real API?**
- Alta fidelidade: Testa integraÃ§Ã£o real com Claude
- Detecta problemas reais: Rate limits, timeouts, parsing
- Custo aceitÃ¡vel: ~R$ 2/run dentro do budget

**Por que Serial Execution?**
- Session state: Testes dependem de sequÃªncia
- Rate limiting: Evita burst de 50+ req/min
- Debugging: Logs mais fÃ¡ceis de seguir

**Por que 12 testes (nÃ£o 50)?**
- Cobertura crÃ­tica: Happy paths + errors + edge cases
- Custo controlado: ~R$ 2/run vs R$ 10+/run
- Manutenibilidade: FÃ¡cil de entender e manter

**O que NÃƒO Ã© testado?**
- Session expiry (30min): Muito longo
- AI routing quality: Trust Claude
- Exact completeness values: VariaÃ§Ã£o aceitÃ¡vel
- Topic detection accuracy: Semantic, best-effort

---

**VersÃ£o:** 1.0.0 (ULTRATHINK methodology applied)
**Ãšltima atualizaÃ§Ã£o:** 2025-11-15
